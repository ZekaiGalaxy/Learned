# Topic-Aware Contrastive Learning for Abstractive Dialogue Summarization

https://arxiv.org/pdf/2109.04994.pdf

#### 任务：

abstractive dialogue summarization

#### 他的方法：

两个辅助任务

* Coherence Detection Objective
  * 跨topic的coherence会比较低
  * 作者让模型去学习coherence的rank关系，通过contrastive learning
    * positive：sliding window
    * negative：permuted sliding window
    * simple contrastive loss (margin)
* Sub-summary Generation Objective
  * 这里也是contrastive loss，但是比较怪异
  * positive：正确的片段生成subsummary；negative：错误的片段
  * 用生成时候的loss作为contrastive
* training paradigm
  * 不是一起训练；而是alternatively updating
