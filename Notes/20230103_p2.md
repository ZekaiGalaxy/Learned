# Retrieval-Free Knowledge-Grounded Dialogue Response Generation with Adapters

https://arxiv.org/pdf/2105.06232.pdf

#### 任务：

做KDG，但是不用传统方法

#### 一般方法：

* Retrieval 
  * TF-IDF
* Selection
* Generation

#### 他的方法：

* 怎么做knowledge injection？弄几个knowledge expert做adapter，implicit knowledge，更lightweight

<img src="https://p.ipic.vip/bpewoy.png" alt="p2" width="700"/>

* Topic Modeling
  * CTM (contextual topic model)
  * 给定L，分成L个主题；给定句子，输出 $w=(w_1,w_2...w_L)$
    * Weighted sum
    * One hot
  * 在训练的时候，最好要context+response，但是测试的时候只有context，有很大gap！
    * 在训练的时候context+response
    * 用context+response的结果去finetune在训练的时候只有context的
* Knowledge Expert Training
  * GPT2 fixed, finetune adapter
  * 这里也有gap！训练数据是一个一个句子，但我们是对话数据集！
    * 把一个一个句子变成对话的style
    * 但是adapter很小，overfit！
      * random replace
* Model Training
  * 用topic model进行expert selection
