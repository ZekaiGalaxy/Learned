# Low-resource Neural Machine Translation with Cross-modal Alignment

https://arxiv.org/pdf/2210.06716.pdf

#### 任务：

lrMT

#### 他的方法：

<img src="https://p.ipic.vip/meq7wb.png" alt="p2" width="600"/>

* 利用多模态的信息来对齐，low resource语言也许能从图中信息，获得更好的representation
* 用图片来和文字对齐
  * word level
    * 我们可以让patch进行attention获得同样长度的“句子”，这样对应的oken之间我们认为是positive，其他是inbatch negative
  * sentence level
    * 图片我们可以在最开始加个cls token
    * 句子我们可以mean pooling
