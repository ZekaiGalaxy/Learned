# Retrieval as Attention: End-to-end Learning of Retrieval and Reading within a Single Transformer

https://arxiv.org/pdf/2212.02027.pdf

#### 任务：

knowledge grounded QA

#### 他的方法：

不再使用传统的retrieve and reading，而是用一个end2end搞定

可以用self attention来做retrieval，用cross attention来做reading

<img src="https://p.ipic.vip/p8so8y.png" alt="p2" width="400"/>

<img src="https://p.ipic.vip/s23ham.png" alt="p2" width="400"/>

* Fusion in decoder (FiD)
  * $P_{gen}(a|x)=\sum P_{gen(a|d_i)}$
* 用self attention来计算query和passage的相似度分数
  * 我们要把一个encoder分成两个部分，分别encode query和passage，然后通过self atention进行交互
  * 你并不需要显式的拆开，而是加mask，不让他们互相看到彼此就行，浅层加mask，深层self attn
  * SA是token level的，得到L_q*L_p的matrix，我们对每个query的单词，在passage中找到最相应的单词作为响应分数，然后对所有query token取mean，也就是所谓的avg(max(attn matrix))
  * 不同的head关注的地方不一样，所以最开始我们可以把每个head得到的relevance score取平均，但是后来实验发现只有一个head是有用的，我们需要改造一下取平均
    * $w=1/n \to w_i \to softmax(w_i/\tau)$
* 这只是计算一个passage和query的分数，我们需要sample很多个passage，但不可能sample整个corpus，需要取舍
  * 我们可以先用BM25去sample一些相邻的
  * 然后又random sample一些，可以用in batch random sampling，把batch里别人的邻居拿过来
* 最后我们还可以监督：在深层和浅层之间进行distilling来进行监督
  * 通过answer，我们可以拿到query，document和answer之间的relevance score
  * 我们之前retrieval的时候也用了relevance score
  * 可以 self distillation
  * 两个relevance score之间可以KL div来监督，保证一致性
  * ！！！最重要的是，我们把target看成是“对”的，用这个来指导retrieval，而不是互相监督，所以我们可以固定target的那个分布不回传梯度！！
* 对于random sample的，我们可以假设relevance是0，从而减少计算量；对于无监督的，即没有answer的，我们可以mask掉一个salient的token，作为query，答案就是mask掉的那个token
