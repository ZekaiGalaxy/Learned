# ADAM: Dense Retrieval Distillation with Adaptive Dark Examples

https://arxiv.org/pdf/2212.10192.pdf

#### 任务：

Dense Retrieval

#### 他的方法：

<img src="https://p.ipic.vip/jud014.png" alt="p2" width="400"/>

* cross encoder和dual encoder各有优点，一般为了快我们都会用dual encoder
* 如何combine两种各有优点的模型？
  * 其实我们可以用知识蒸馏！
* 一般的知识蒸馏还是太sharp，虽然有temperature可以调节，但其实看attention score的分布还是太sharp
  * 于是可以让data不那么sharp，hard negative还不够hard，positive太positive了
  * 我们可以用mixup：在negative前面拼接positive，这样就更hard了
  * positive可以mask掉一些信息，加入noise，让它不这么positive
* 还可以有self paced learning
  * 对于teacher confidence，我们可以排序
  * 可以每个epoch多一点sample的数量
  * 也可以threshold，每个epoch增加一点
