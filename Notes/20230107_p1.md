# LEARNING MULTIMODAL DATA AUGMENTATION IN FEATURE SPACE

https://arxiv.org/pdf/2212.14453.pdf

#### 任务：

多模态的数据增广，很多多模态任务都是对单模态进行增广，可能会有gap

#### 他的方法：

<img src="https://p.ipic.vip/ntften.png" alt="p2" width="400"/>

在feature space进行增广

* 假设原来fusion之前 $F_{before}$ ,fusion之后是 $F_{after}$
* 那么就是用generator增广通过fusion layer的那些hidden
  *  $h=F_{before}(x),h^\*=g(F_{before}(x)),y=F_{after}(h,h^\*)$
* loss
  * 我们数据增广想要达到最大效果，就模仿adversarial loss的思想，去max task loss，这样才能学到的更多
  * 但同时，我们不能太偏离，就需要正则化：KL来监督consistency of output distributions
  * 同时我们generator模型是VAE，要有个reconstruction loss
  * $L_{task}+KL(y,y^*)+L_{recon}$
* VAE的选择，输入是N个模态的hidden1$h_1,h_2...h_n$
  * 拼接起来，看成一个向量：MLP-VAE
  * 看成一个seq，attention-VAE，self attention+ffn
