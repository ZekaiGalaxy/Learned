# Conditional Bilingual Mutual Information Based Adaptive Training for Neural Machine Translation

https://arxiv.org/pdf/2203.02951.pdf

### 任务：

我们普通lm loss对所有token一视同仁，但是应该adaptive，有的token重要有的不重要

### 别人方法：

BMI

利用mutual information来做weight

* $MI(x,y_i)=log \frac{p(x,y_i)}{p(x)p(y_i)}$
* 为什么要做BMI
  * 一维来看，target domain本身有些词关键，有一些不关键
  * 二维来看，src-tgt的mapping

### 他的方法：

CBMI，不仅像BMI一样考虑context，也考虑生成过程中的target，context aware + target aware

- token level

  $CBMI(x,y_i|y_{i})$

  $ =log \frac{p(x,y_i|y_{i})}{p(x|y_{i})p(y|y_{i})} $

  $=log \frac{p(x|y_{i})p(y|x,y_{i})}{p(x|y_{i})p(y|y_{i})}$

  $=log \frac{p_{NMT}}{p_{LM}}$

  - normalize

    * $(CBMI- \mu)/\sigma$
    * Scale (now in (0,1))

* sentence level

  * upweight good sentences

