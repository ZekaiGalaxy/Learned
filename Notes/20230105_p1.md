# Multi-View Sequence-to-Sequence Models with Conversational Structure for Abstractive Dialogue Summarization

https://arxiv.org/pdf/2010.01672.pdf

#### 任务：

abstractive dialogue summarization

#### 问题：

我们要关注到不同的topic shift，也就是不同的view

* topic view
  * 用C99方法segment
* stage view
  * 用HMM
* Global view
* discrete view

#### 他的方法：

<img src="https://p.ipic.vip/6wt3cf.png" alt="p2" width="700"/>

* 在encoder中对每个view（若干个block）提取出一个hidden作为信息
  * $V_k=\\{b_1,b_2...b_n\\},b_i=\\{x_{i1}...x_{in}\\}$
  * 首先对每个block进行encode，为了每个block得到一个token，可以在开头加一个special token，把这个token的信息作为block的信息
  * 现在我们有n个block，把他们整合成一个：用LSTM中的last hidden

* 在decoder中对k个hidden进行attention
  * 现在我们有k个hidden，要在attention中整合
  * 在encoder-decoder attention中，本质是decoder中的每个token获得一个在encoder空间中的向量，整合进去（decoder的作为query），如果参考的只有单个hidden，那么就相当于给出decoder中每个单词在这个空间中的属性值分布，再乘以一个单位向量，再考虑multihead的话，我们就能得到不同空间的信息，所以合理
  * $h_E=\\{h_1,...h_n\\} \to \\{s_1,...s_n\\}*e$
  * 如果要整合单个view的信息，已经可以了；现在考虑多个view，就要重要性加权
    * $softmax(WV_k+b)$
    * $softmax(tanh(WV_k+b)^Tv)$

