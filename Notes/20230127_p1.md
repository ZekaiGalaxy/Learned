# Adapting a Language Model While Preserving its General Knowledge

https://arxiv.org/pdf/2301.08986.pdf

#### 任务：

DA：domain adapting

#### 他的方法：

我们希望在DA的时候保留general knowledge，也就是说让保存gk的参数尽量不更新

<img src="https://p.ipic.vip/nrdz2j.png" alt="p2" width="400"/>

* 怎么找到general knowledge
  * 定义attention为保存knowledge的地方
  * 要定义每个head对于general knowledge的重要性
  * 那么我们就要定义一个和general knowledge有关的loss，然后求梯度，用梯度变化来反应重要性
  * 这个loss：LM是否robust，我们输入两次input（因为模型中本身就有random mask，所以就相当于加了某种noise），然后求出loss，这样的话我们可以用KL散度来衡量robustness（robustness：两次结果的差距）
* 怎么“尽量不更新”
  * 我们根据每个head进行打分，然后对梯度进行element wise gate，每个梯度乘以一个0-1的权值，这样就算是“soft mask”
  * 既然我们已经得到了重要性分数，我们就可以放缩得到soft mask
  * $\partial_{attn} = (1-tanh(norm(I)))* \partial_{attn}$
* 辅助任务
  * 更好的区分general knowledge和domain knowledge，那我们就可以利用contrastive learning
  * 如果已经区分过了参数（有加权），那么我们就可以把没有加权的作为original，加了权的作为positive
