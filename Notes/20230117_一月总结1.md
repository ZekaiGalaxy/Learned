## 思想

* #### 分层

  * multi-view dialogue
    * topic
    * stage
    * global，discrete
    * past/future：生成多步，从未来看现在

* #### Curriculum learning

  * 可以根据一开始model预测的acc，从learned到not learned
  * 从pure（filter过的）到noise（neighbor）
  * self paced learning
    * 设置threshold，每个epoch多看一些难的data，直到看完

* #### 分治

  * 在distillation中对于task agnostic进行distill，对于task specific进行pruning
  * 对vision信息和language信息不同处理
  * 知识对话中各个部分有不同的功能，可以加上标签训练
  * 在distillation中，target class和非target class不应该被同等对待，应该不同权值
  * 不同质地的，比如abstractive和subtractive
  * 比如加noise的时候不同参数可能就需要不同对待
    * 比如ffn和attn的参数矩阵的rank和std就很不一样
  * dropout的是task-free还是task-driven的参数
  * contrastive对所有数据一视同仁，应该不同acc区别对待
  * 不同的attention head
  * cluster based

* #### 筛选

  * persona中相关的语句只有一句，如果全部用会有误导性
  * attention看的太多了，有时候我们只需要一部分的attention，可以做个hierachical selection
    * Global-section-patch
  * 有时候筛选需要考虑两方面可能矛盾的因素，比如relevance和redundancy
    * 可以用矩阵的形式，对角线是相关性，其他是redundancy，
    * 那么我们取最大determinant的submatrix，这个就是最大化所取向量的volume（尽量大且正交）
    * 也可以 $argmax(sim(x,x')-\alpha sim(x_i,x_j)$
 
* #### geometry

  * “邻居”的利用
  * pairwise，triplet wise（angle）
    * pairwise可以是sim，也可以是mutual information
    * $p(e_i|e_j)=exp^{(-\frac{||e_ie_j^T||}{\sigma})}$
    * $p(e_i|e_j)=softmax(-d(e_i,e_j))$
  * margin的概念
    * 比如contrastive用cos但是没有加decision boundary

* #### self correct

  * 先生成一些，然后有一部分好的，有一部分坏的，坏的里面有邻居是好的，根据这个finetune

* #### callibration

  * 有时候模型会学出问题无关，data有关的捷径，我们需要remove bias
    * LM bias用 $logP_{LM}-logP_{baseline}$
    * Attention bias可以在inference的时候控制temperature

* #### multi-granularity

  * 上位概念-具体
  * word level, sentence level
  * Token, span, sample
  * global matching, local matching



## 方法

* #### alignment

  * 利用互相生成任务来align，mask一个，利用另外一个的predict
  * 对齐的时候需要project到另一个空间
  * 对齐也可以用self attention，但是最好加个type embedding
  * 异质信息不一样的地方
    * attention的分布
  * 可以对相似度矩阵用avg(max())作为响应分数

* #### distillation

  * 可以用来“同时利用优点“
    * 比如cross encoder和dual encoder
  * 浅层和深层可以self distillation
    * 比如context，response和target之间
    * 但是需要保持target不回传梯度
  * 蒸馏时teacher model需要more balanced，”每个参数都有用处“
    * 多次forward，用consistency约束
  * teacher和student的data分布要有consistency

* #### auxiliary task

  * coherence低那就去设计学习coherence的rank关系，可以用contrastive

* #### contrastive

  * negative构造
    * dropout
    * template
    * modify
    * in batch
    * 去掉salient的
    * domain based（same domain）
    * adversarial
  * positive可以加上noise变得不那么positive，negative可以在前面拼接positive变得不那么negative
  * tangential contrast
    * 选择了一个球作为邻域作为正样例，负样例可以通过interpolate
  * contrastive的内容
    * content
    * emotion
    * attribute
    * concept，keyword
    * student，teacher

* #### data augmentation

  * adversarial，最大化task loss
  * multimodal data可以在fusion前在feature层进行augmentation
  * teacher model的silver label
  * token shuffling
  * feature cutoff
  * dropout mask
  * different views
  * synonym replacing
  * random deletion
  * token level，phrase level

* #### prompt

  * soft
  * perturbed
  * interpolated
  * topic aware
  * Curriculum



## 结构设计

* #### transformer structure

  * 研究ffn的结构
    * 可以用softmax研究x和x+ffn(x)的分布变化
    * 相当于是对一系列的value向量进行更新，只要value向量和词向量同方向，就会鼓励这个单词的生成
  * 研究attn
    * 可以用静态的key value memory
  * self attn是天然的retrieval，cross attention是天然的reading

* #### mixed expert

  * 像是googlenet里面一样，多个模块（adapter，attention，ffn）并联，预测分布
  * 多个hidden送进cross attention里面
    * 也可以有层次关系，不一定是全并联，可以并联+串联
  * fusion in decoder，采取多个decoder， $P_{vocab}(w)=\Sigma g_iP_{d_i}(w)$

* #### vocab injection

  * 在softmax的时候加bias
    * $softmax(Wx+b+b_{injection})$
  * posthoc injection
    * 利用梯度来优化

* #### Vocab selection

  * vocab有两种来源，每次vocab由一种来源提供
  * $P_{vocab}=\gamma P_A+(1-\gamma)P_B$
  * 监督 $\gamma$



## 模块细节

* #### sample

  * $p \sim  exp(x_1+x_2)$可以是两个约束条件，来控制
  * 比如 $\beta sim(x,x')+\alpha(v(x)-v(x'))$
  * $(\frac{P_1(y|x)}{P_2(y|x)})^\alpha$ 如果让下面是baseline，那么就可以控制突出上面模型的attribute（比如毒性）

* #### distance

  * EMD，edit distance
  * 多个分布之间可以用X-divergence
    * $\Sigma KL(\hat p||p)+KL(p||\hat p)$
  * 可以采取rank类的distance
    * 比如probing，需要弄几次才能达到正确答案（正确答案排第几）
    * 排名倒数之和

* #### distribution

  * uniform + std(W)
  * Gaussian
    * 利用saliency score来决定方差项
    * $N(0,diag(W_r^2),W_r=\frac{|r|-min(|r|)}{max(|r|)-min(|r|)}$
  * increasing, uniform, decreasing, spindle, bottleneck

* #### weighted

  * 先指数函数后保持不变
    * $\alpha x^{\gamma}$
  * order
    * $f(o)=\alpha^{\frac{o_{max}-o}{o_{max}-o_{min}}}$
  * annealing
    * 0-0.5保持，0.5-0.75线性到1，0.75-1.0保持

* #### graph

  * relation triple
    * transition based
      * $||h+r-t||$
    * rotation based
      * $||h*r-t||$
    * tensor composition based
      * $||h^tdiag(M_r)t||$
    * $e_{ij}=a^T[W_ih_i;W_jh_j;W_rh_{i-j}]$

* #### aggregate hidden

  * Lstm for $h_1,h_2...h_n$
  * MLP
  * self attention+ffn
  * word level
    * $x_1,x_2...x_n ;y_1,y_2...y_n$
    * cos matrix and 2-direction mean pooling
  * 把hidden放进decoder中，可以直接加在self attention后面
    * $x'=Wh+x+b$
  * $[x;y;|x-y|;x*y]$

* #### extract hidden

  * mean pooling
  * max pooling
  * [CLS]

* #### hidden projection

  * $x,y \to R^d$
    * $softmax(W[x;y]+b)$
  * $x,y \to R$
    * $sigmoid(W[x;y]+b)$
  * $x,y,a \to R$
    * $(W_aa)^Ttanh(W_xx+W_yy+b)$
  * $V_1,V_2...V_k \to R^k$
    * $softmax(tanh(WV_k+b)^Tv)$

* #### strategy

  * 不一定是onehot，可以预测一个分布
  * 然后用strategy codebook

* #### saliency/sensitivity

  * Fisher Information matrix
  * $I(x)=|L(\theta)-L(\theta_{-i})|=\theta_i^t\partial_x L(]tehta)$
  * gradient的L1 norm
  * attention score
  * 加上l1 norm，看谁的变化大



## 训练技巧

* #### Overfitting

  * topk layer finetune
  * weight decay
  * mixout
    * 用pretrain的weight代替一部分参数（相当于没训）
  * 加noise
    * $KL(f(x)||f(x+\epsilon))$
  * Dropout 

* #### special token

  * 生成图片（special token的地方生成描述）
  * 原封不动的copy
  * 进行知识抽取

* #### training paradigm

  * loss不是一起训练而是alternative updating
  * 可以先context+response产生结果，然后只有context去finetune刚才的结果



## 工具箱

* #### retrieval

  * Non param
    * TFIDF
  * param
    * prompt
    * COMET 产生自然语言知识
  * 当知识产生矛盾的时候如何处理？

* #### topic modeling

  * CTM，可以给出主题和概率
  * C99，按照主题分segment

* #### keyword

  * Verb, emotional words
    * NLTK sentiment, NLTK POS tagging, lemmatization
  * RAKE
  * Wordpiece

* #### generate data

  * NLI
  * contradiction，entailment
  * prompt based
