# STGN: an Implicit Regularization Method for Learning with Noisy Labels in Natural Language Processing

https://aclanthology.org/2022.emnlp-main.515.pdf

### 任务：

改进优化器

### 他的方法：

一般的sgd其实都是noisy gradient，也就是我们算出了某个gradient但是我们不直接update，而是先加个gaussian noise然后再update

* 我们应该对梯度有所区别，这里用的是instance wise，比如一个sample是correct sample还是incorrect sample
  * 我们可以对incorrect sample多加点noise，来防治过拟合，这也是overfitting的初衷
  * 而对correct sample就少一点，这样训练更加稳定
  * 同时gaussian可能采样到极端值，所以应该改成uniform更加stable
