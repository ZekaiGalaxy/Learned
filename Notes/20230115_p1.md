# Constructing Highly Inductive Contexts for Dialogue Safety through Controllable Reverse Generation

https://arxiv.org/pdf/2212.01810.pdf

#### 任务：

减少毒性

#### 他的方法：

<img src="https://p.ipic.vip/8ijma6.png" alt="p2" width="600"/>

* context和response的毒性很相关，某种类型的context容易引发毒性（inductive）
  * 因此用reverse generation
* 同时context本身毒性大，response毒性也大
* 首先control context的category，我们可以用prompt
* 其次control context毒性，我们可以用vocab层面的加强：
  * 可以训练三个LM模型，分别是正常LM，reverse LM和toxic reverse LM
  *  $\frac{P_\theta(c_i|r)}{P_\phi(c_i|r)}$
  *  $\frac{P_\theta(c_i|r)}{P_\gamma(c_i|r)}$
  * 之间相互除以就可以代表放大什么因素，比如toxic的除以不toxic的就相当于log之后减去一个baseline，于是我们就更专注生成toxic的内容，另一方面也需要加强连贯性，同时我们可以用幂次来调节度

