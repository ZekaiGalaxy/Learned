# PATS: Sensitivity-aware Noisy Learning for Pretrained Language Models

https://arxiv.org/pdf/2210.12403.pdf

### 任务：

PTM

### 他的方法：

一般我们都是加nosie不区别对待，但是他提出我们要对那种sensitive或者很重要的参数少加点noise，这样表现更加稳定，然后对那种不重要的参数多加点noise，这样就更容易到global minima

* saliency $s_j = \theta_j \partial_{\theta_j}L(\Theta)$
