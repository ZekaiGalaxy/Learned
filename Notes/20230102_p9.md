# EfficientVLM: Fast and Accurate Vision-Language Models via Knowledge Distillation and Modal-adaptive Pruning

https://arxiv.org/pdf/2210.07795.pdf

#### 任务：

减少参数

#### 他的方法：

* Task agnostic
  * Distill
* Task specific
  * Modal adaptive pruning
  * 哪些层是重要的？特别是vision和language层的敏感性是不同的
  * $\theta \odot z, z \in [0,1]$, whether to prune
  * $E_z[\sum L(x,y;\dot \theta) + \lambda ||\theta||_2]$ 
  * gradient based method

<img src="https://p.ipic.vip/atw5bn.png" alt="p2" width="300"/>

