# Transformer Feed-Forward Layers Build Predictions by Promoting Concepts in the Vocabulary Space

https://arxiv.org/pdf/2203.14680.pdf

#### 任务：

对transformer的ffn layer进行研究

#### 他的方法：

<img src="https://p.ipic.vip/w54y3t.png" alt="p2" width="400"/>

ffn其实在对output vocab进行改变

* 假设每个x都是为了输出做准备，我们就可以看ffn前后的vocab distribution来看ffn做了什么
* $softmax(E(x+ffn(x)))$  vs  $softmax(Ex)$
* $ffn(x) = f(W_kx)W_v=\sum m_iv_i$，其中我们把后面的矩阵视作某些和vocab有关的value vector，这样我们也可以解耦出一系列的subupdates on value vectors
* 对于vocab层面的更新，我们可以看
  * $p(w|x+mv) \sim exp(e_wx)*exp(e_wmv)$
  * 可以看出第一项是固定的bias
  * 后一项是subupdate，如果某个单词的embedding和mv是同方向的，那么就更多出现
  * 如果反方向，那么就减少出现

#### 两个应用

* toxic
  * 找到和toxic相关的subupdates然后"turn on", "turn off"
* early stopping
  * 可视化updates，如果哪步update不是那么明显（前后两步overlap高），我们就停止了
