# Contextual Fine-to-Coarse Distillation for Coarse-grained Response Selection in Open-Domain Conversations

https://arxiv.org/pdf/2109.13087.pdf

### 任务：

retrieval response

### 别人方法：

一般来说有coarse selection（BM25）+ fine selection

但是BM25可能不能解决对话中的topic shift的问题，这样其实overlap就会很低

### 他的方法：

* 有数据集(C,R)，我们拿query C去匹配最相似的context，然后topk response作为coarse selection
* fine selection也有问题：
  * two tower model（两个encoder+sim classifier）交互太单一了，就是个dot product
  * one tower model（拼接在一起求单个分数）效率太低了
  * 所以我们可以做一个distillation，这样对于negative classes也有一些暗知识
